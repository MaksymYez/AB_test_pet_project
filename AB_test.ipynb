{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze A/B Test Results\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "- [Introduction](#intro)\n",
    "- [Part I - Probability](#probability)\n",
    "- [Part II - A/B Test](#ab_test)\n",
    "\n",
    "\n",
    "<a id='intro'></a>\n",
    "### Introduction\n",
    "\n",
    "A/B tests are very commonly performed by data analysts and data scientists. In this notebook I will demonstrate my ability of conducting A/B test using Python.\n",
    "\n",
    "In this project, I will be working to understand the result of an A/B test for a fictional e-commerce company. Specifically conversion rates for 2 different pages on their website. Throughout this notebook, I will start by calculating inital statistics and probabilities of conversion in the data set, than I will proceed to an A/B test using hypothesis testing. In the end I will write a conclusion and my personal recomendations for the company.\n",
    "\n",
    "<a id='probability'></a>\n",
    "#### Part I - Probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first read into our data set and look into the structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ab_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifying the ammount of rows in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294478"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking out the ammount of unique users in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Calculating the proportion of users converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12104245244060237"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query(\"converted == '1'\").nunique()[0]/df.nunique()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I assume, that by design, `control group` should reciev `old_page` and `treatment group` should receive `new_page`. I would like to check if this is consistently true for this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "treat_old = df.query(\"group == 'treatment' & landing_page != 'new_page'\").nunique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_new = df.query(\"group != 'treatment' & landing_page == 'new_page'\").nunique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3893"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treat_old + control_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there are some inconsistencies in terms of group and the page they recieve. We will deal with these inconsistencies a bit later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would also like to see if any cells have missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id         0\n",
       "timestamp       0\n",
       "group           0\n",
       "landing_page    0\n",
       "converted       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that this data set is clean and has no missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I would like to remove inconsitencies between the group in our experiment and page which they recieve. I will create a new data frame which will remove situations where `control group` recieved new page and vice versa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.query(\"group == 'treatment' & landing_page == 'new_page'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.append(df.query(\"group == 'control' & landing_page == 'old_page'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[((df2['group'] == 'treatment') == (df2['landing_page'] == 'new_page')) == False].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I would like to see the ammount of unique users who participated in our experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id         290584\n",
       "timestamp       290585\n",
       "group                2\n",
       "landing_page         2\n",
       "converted            2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I would also like to check if there are any dublicates in our data set. If there are any, we will remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['user_id'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "2893   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2['user_id'].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['user_id'].drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['user_id'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I would like to calculate the probability of an individual in our data set to convert regardless of the page they receive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted\n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959667567149027"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_prob = df2[df2['converted'] == 1].shape[0]/df2.shape[0]\n",
    "conv_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bellow, we will calculate what are the probability of conversion for control and treatment groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1203863045004612"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_prob_cont = df2.query(\"group == 'control' & converted == '1'\").shape[0]/ df2[df2['group'] == 'control'].shape[0]\n",
    "conv_prob_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11880724790277405"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_prob_treat = df2.query(\"group == 'treatment' & converted == '1'\").shape[0]/ df2[df2['group'] == 'treatment'].shape[0]\n",
    "conv_prob_treat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, I would like to see what proportion of users are in treatment group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000636646764286"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_p_prob = df2.query('landing_page == \"new_page\"').shape[0]/df2.shape[0]\n",
    "new_p_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From my initial observation, it seems like there is no signignificant impact of new page on conversion rate**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ab_test'></a>\n",
    "### Part II - A/B Test\n",
    "\n",
    "To begin my A/B test, we have to establish our null and alternative hypothesis as well as Type I error rate. In this A/B test we are comparing conversion rate between old and new version of web page. As a result I belive our null hypothis should be that our old page is either the same or better than the new one and alternative hypothesis should be that our new page is strictly better than old one. In mathematical terms this will look like this:\n",
    "\n",
    "**$H_{0} = $$p_{old}$ - $p_{new}$ >= 0**  \n",
    "**$H_{1} = $$p_{old}$ - $p_{new}$ < 0**\n",
    "\n",
    "For this experiment I will also settle for 5% Type I error rate as I believe it is sufficiently accurate for the purpose of our experiment and generally is accepted by specialists in this field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will begin setting up our hypothesis test. We will assume that under the null hypothesis, $p_{new}$ and $p_{old}$ both have \"true\" success rates equal to the **converted** success rate regardless of page - that is $p_{new}$ and $p_{old}$ are equal. Furthermore, we assume they are equal to the **converted** rate in our **data set** regardless of the page.\n",
    "\n",
    "We will use a sampe size for each page equal to the one in our data set.\n",
    "\n",
    "Than, we will perform sampling distribution for the **difference** in convertions between two pages over 10,000 iteration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert rate** for $p_{new}$ under the null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959667567149027"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_new = df2[df2['converted'] == 1].shape[0]/df2.shape[0]\n",
    "P_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert rate** for $p_{old}$ under the null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959667567149027"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_old = df2[df2['converted'] == 1].shape[0]/df2.shape[0]\n",
    "P_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of new pages shown in our data set $n_{new}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145310"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_new = df2[df2['group'] == 'treatment'].nunique()[0]\n",
    "N_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of old pages shown in our data set $n_{old}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145274"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_old = df2[df2['group'] == 'control'].nunique()[0]\n",
    "N_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets simulate $n_{new}$ transactions with a convertion rate of $p_{new}$ under the null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_page_converted = df2['converted'].sample(N_new, replace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets simulate $n_{old}$ transactions with a convertion rate of $p_{old}$ under the null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_page_converted = df2['converted'].sample(N_old, replace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally find the difference between convertion rate for new page and an old page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11969582272383181"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_page_converted.sum()/N_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12083373487341162"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_page_converted.sum()/N_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0011379121495798117"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_page_converted.sum()/N_new - old_page_converted.sum()/N_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will create a sampling distribution by simulating difference 10,000 times. I will use bootstraping method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = []\n",
    "for _ in range(10000):\n",
    "    new_page_converted = df2['converted'].sample(N_new, replace = True)\n",
    "    new_page_conv_prob = new_page_converted.sum() / N_new\n",
    "    old_page_converted = df2['converted'].sample(N_old, replace = True)\n",
    "    old_page_conv_prob =  old_page_converted.sum()/N_old\n",
    "    diff = new_page_conv_prob - old_page_conv_prob\n",
    "    diffs.append(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0015790565976871451"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_diff = conv_prob_treat - conv_prob_cont\n",
    "obs_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when we simulated difference between convertion rates 10,000 times, we can plot our distribution. We can also plot an actual difference observed in our data set on the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(diffs);\n",
    "plt.axvline(x=obs_diff, c='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will calculate a proportion of our mean differences which are greater than our observed difference in data set and find our p_value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0015790565976871451"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_diff = conv_prob_treat - conv_prob_cont\n",
    "obs_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs_array = np.array(diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9087"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pval = (diffs_array > obs_diff).mean()\n",
    "pval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Double Check with NP method**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will double check our value from the previous approach by using numpy random.binomial function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_converted_simulation = np.random.binomial(N_new, P_new, 10000)/N_new\n",
    "old_converted_simulation = np.random.binomial(N_old, P_old, 10000)/N_old\n",
    "p_diffs_2 = new_converted_simulation - old_converted_simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00051831, -0.00192932, -0.00057361, ...,  0.00101672,\n",
       "       -0.00011902, -0.00089711])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_diffs_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9033"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(p_diffs_2 > obs_diff).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the p_value which we calculating using np method is identical to the one from the previous exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**By calculating a proportion of our mean differences which are greater than our observed difference in data set, we calculated a p value which indicated the probability of observing our statistic if the null hypothesis is true. The P value of 0.91 is greater than our alpha level of 0.05 and as a result, we fail to reject a null hypothesis. This means, that our fictional company should not procced to implement a new page and should stay on the old one.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
